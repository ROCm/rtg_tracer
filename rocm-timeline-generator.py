#!/usr/bin/env python
"""

Parse files generated by HSA_TOOLS_LIB rtg_tracer.so and generate a chrome://tracing JSON file.

HSA sampel output
-----------------
    HSA: pid:4905 tid:140302773952640 hsa_agent_get_info (agent_94179622800240, 17, 0x7ffd086dfebc) ret=0 @1811961275577532 +152

HIP sample output
-----------------
    HIP: pid:4905 tid:140302773952640 hipFree  ret=0 @1811962118575233 +34010

strace/ltrace -tttT sample output {beta}
----------------------------------------

    1555950992.253210 fclose(0x7f1d799ab620 <unfinished ...>
    1555950992.253296 free(0x6d0c90)                 = <void> <0.000067>
    1555950992.253390 <... fclose resumed> )         = 0 <0.000176>
    1555950992.253415 __fpending(0x7f1d799ab540, 0, 0x7f1d799ac780, 0) = 0 <0.000078>
    1555950992.253523 fileno(0x7f1d799ab540)         = 2 <0.000064>

HCC sample output (Deprecated, HCC_PROFILE=2 mode, useful for the old 'rpt' reporting tool)
-------------------------------------------------------------------------------------------

    profile: barrier;  depcnt=0,acq=none,rel=none;     19.0 us;  83825272529988; 83825272549028; #0.0.1;
    profile:  kernel;  _ZN12_GLOBAL__N_110hip_fill_nILj256EPjmjEEvT0_T1_T2_;     11.2 us;  83831226310426; 83831226321626; #0.0.2;
    profile: barrier;  depcnt=0,acq=sys,rel=sys;     10.2 us;  83831226329626; 83831226339866; #0.0.3;
    profile: barrier;  depcnt=0,acq=none,rel=none;     18.1 us;  83825592607250; 83825592625330; #0.1.1;
    profile: barrier;  depcnt=1,acq=none,rel=none;     25.8 us;  83831227971384; 83831227997144; #0.1.10; deps=#0.1.9
    profile:    copy;  DeviceToDevice_async_fast;     13.1 us;  83831227978264; 83831227991384; #0.1.9; 4004 bytes; 0.0 MB; 0.3 GB/s;

"""

from __future__ import print_function
import getopt
import json
import os
import re
import subprocess
import sys

RE_HSA              = re.compile(r"HSA: pid:(\d+) tid:(\d+) (.*) (\(.*\)) ret=(.*) @(\d+) \+(\d+)")
RE_HSA_DISPATCH_HOST= re.compile(r"HSA: pid:(\d+) tid:(\d+) dispatch queue:(.*) agent:(\d+) signal:(\d+) name:'(.*)' tick:(\d+) id:(\d+) workgroup:{(\d+),(\d+),(\d+)} grid:{(\d+),(\d+),(\d+)}")
RE_HSA_DISPATCH     = re.compile(r"HSA: pid:(\d+) tid:(\d+) dispatch queue:(.*) agent:(\d+) signal:(\d+) name:'(.*)' start:(\d+) stop:(\d+) id:(\d+)")
RE_HSA_BARRIER_HOST = re.compile(r"HSA: pid:(\d+) tid:(\d+) barrier queue:(.*) agent:(\d+) signal:(\d+) dep1:(\d+) dep2:(\d+) dep3:(\d+) dep4:(\d+) dep5:(\d+) tick:(\d+) id:(\d+)")
RE_HSA_BARRIER      = re.compile(r"HSA: pid:(\d+) tid:(\d+) barrier queue:(.*) agent:(\d+) signal:(\d+) start:(\d+) stop:(\d+) dep1:(\d+) dep2:(\d+) dep3:(\d+) dep4:(\d+) dep5:(\d+) id:(\d+)")
RE_HSA_COPY         = re.compile(r"HSA: pid:(\d+) tid:(\d+) copy agent:(\d+) signal:(\d+) start:(\d+) stop:(\d+) dep1:(\d+) dep2:(\d+) dep3:(\d+) dep4:(\d+) dep5:(\d+)")
#TODO handle HIP args
RE_HIP              = re.compile(r"HIP: pid:(\d+) tid:(\d+) (.*)  ret=(.*) @(\d+) \+(\d+)")
RE_HCC_PROF_TS_OPX  = re.compile(r"profile:\s+(\w+);\s+(.*);\s+(.*) us;\s+(\d+);\s+(\d+);\s+#(\d+\.\d+\.\d+);\s+(.*)")
RE_HCC_PROF_TS_OP   = re.compile(r"profile:\s+(\w+);\s+(.*);\s+(.*) us;\s+(\d+);\s+(\d+);\s+#(\d+\.\d+\.\d+);")
RE_HCC_PROF_TS      = re.compile(r"profile:\s+(\w+);\s+(.*);\s+(.*) us;\s+(\d+);\s+(\d+);")
RE_HCC_PROF_OP      = re.compile(r"profile:\s+(\w+);\s+(.*);\s+(.*) us;\s+#(\d+\.\d+\.\d+);")
RE_HCC_PROF         = re.compile(r"profile:\s+(\w+);\s+(.*);\s+(.*) us;")
RE_STRACE_UNFINISED = re.compile(r"(\d+)\.(\d+) (.*) <unfinished \.\.\.>")
RE_STRACE_RESUMED   = re.compile(r'(\d+)\.(\d+) <\.\.\. (\w+) resumed> .* = <?(["\w/\.-]+)>? <(.*)>')
RE_STRACE_COMPLETE  = re.compile(r"(\d+)\.(\d+) (.*) = (-?<?\w+>?) <(.*)>")

count_skipped = 0
count_hip_api = 0
count_hip_missed = 0
count_hcc_prof_ts_opx = 0
count_hcc_prof_ts_op = 0
count_hcc_prof_ts = 0
count_hcc_prof_op = 0
count_hcc_prof = 0
count_hcc_prof_missed = 0
hip_pids = {}
count_gap_duplicate_ts = 0
count_gap_wrapped = 0
count_gap_okay = 0
count_strace_unfinished = 0
count_strace_resumed = 0
count_strace_complete = 0
count_hsa_api = 0
count_hsa_dispatch_host = 0
count_hsa_dispatch = 0
count_hsa_barrier_host = 0
count_hsa_barrier = 0
count_hsa_copy = 0
count_hsa_missed = 0
count_rccl_info_allreduce = 0
count_rccl_missed = 0

workgroups = {}

hsa_pids = {}
hsa_queues = {}

# HIP can nest its calls, so the opnum is not reliable (bug in HIP trace).
# Also, hipLaunchKernel is printed without a closing HIP print.
# The hipLaunchKernel message should amend the preceeding kernel launch info.
hip_events = {}

# HIP's hipExtLaunchMultiKernelMultiDevice will nest many calls to hipLaunchKernel
hip_multikernel = {}

# HIP/rocclr for ease of use we want monotonically increasing pids
hip_rocclr_pids = {}
hip_rocclr_next_pid = 0
def get_hiprocclr_pid(pid):
    global hip_rocclr_pids
    global hip_rocclr_next_pid
    if pid not in hip_rocclr_pids:
        hip_rocclr_pids[pid] = hip_rocclr_next_pid
        hip_rocclr_next_pid += 1
    return hip_rocclr_pids[pid]

# HSA can nest its calls.
hsa_events = {}

# The set of GPUs is maintained for pretty-printing metadata in the chrome://tracing output.
devices = {}

# Per device HCC timestamps, for gap analysis
gaps = {}
gap_names = {}

# strace/ltrace need to track unfinished calls by name
strace_unfinished = {}

# do we replace hipModuleLaunchKernel et al with the actual kernel names
replace_kernel_launch_with_name = False

# organizing HIP calls into stream groups needs a pid to name mapping
hip_stream_output = False
hip_stream_pids = {}

def print_help():
    print("""
rocm-timeline-generator.py

arguments:
    -f              show flow events from host to HSA queue
    -g              add gap events to output
    -h              this help message
    -k              replace HIP kernel launch function with actual kernel names
    -o filename     output JSON to given filename
    -s              HIP calls with hipStream_t args are grouped separately
    -v              verbose console output (extra debugging)
    -w              print workgroups sizes, sorted
""")
    sys.exit(0)

try:
    opts,non_opt_args = getopt.gnu_getopt(sys.argv[1:], "fghko:svw")
    output_filename = None
    show_gaps = False
    show_flow = False
    verbose = False
    print_workgroups = False
    for o,a in opts:
        if o == "-f":
            show_flow = True
        elif o == "-g":
            show_gaps = True
        elif o == "-h":
            print_help()
        elif o == "-k":
            replace_kernel_launch_with_name = True
        elif o == "-o":
            output_filename = a
        elif o == "-s":
            hip_stream_output = True
        elif o == "-v":
            verbose = True
        elif o == "-w":
            print_workgroups = True
        else:
            assert False, "unhandled option"
except getopt.GetoptError as err:
    print(err)
    sys.exit(2)

if not output_filename:
    output_filename = "out.json"
    print("Writing chrome://tracing output to '%s' (use -o to change name)" % output_filename)
else:
    print("Writing chrome://tracing output to '%s'" % output_filename)

def vprint(msg):
    if verbose:
        print(msg)

out = open(output_filename, "w")
out.write("""{
"traceEvents": [
""")

def kern_name(full_string):
    """Parse HIP kernel name information."""
    return full_string.strip().split()[1][1:-1]

def kern_to_json(full_string, use_kernel_name=True):
    """Parse HIP kernel information into an 'args' JSON object."""
    parts = full_string.strip().split()
    name = parts[1][1:-1]
    gridDim = parts[2].split(':')[1]
    groupDim = parts[3].split(':')[1]
    sharedMem = parts[4].split(':')[1]
    stream = parts[5].split(':')[1]
    if use_kernel_name:
        return '{"name":"%s", "gridDim":"%s", "groupDim":"%s", "sharedMem":"%s", "stream":"%s"}'%(
                name, gridDim, groupDim, sharedMem, stream)
    else:
        return '{"gridDim":"%s", "groupDim":"%s", "sharedMem":"%s", "stream":"%s"}'%(
                gridDim, groupDim, sharedMem, stream)

def hip_args_to_json(full_string):
    """Parse HIP call parameters into an 'args' JSON object.

    Example:
        hipMemcpyHtoDAsync (0x7fb64a635100, 0x7fbf05503500, 4004, stream:0.2)

    """
    parts = full_string.strip().split()
    counter = 0
    ret = '{'
    for part in parts[1:]:
        if counter > 0:
            ret += ', '
        if part[0] == '(':
            part = part[1:]
        if part[-1] in [')',',']:
            part = part[0:-1]
        if ':' in part:
            try:
                name,value = part.split(':', 1) # hipCtx_t args have an extra ':'
                ret += '"%s":"%s"' % (name,value)
            except:
                print("uh oh")
                print(part)
                print(full_string)
                raise
        else:
            ret += '"arg%d":"%s"' % (counter,part)
        counter += 1
    ret += '}'
    return ret

def hip_get_stream(full_string):
    global hip_stream_pids
    pidstr = None
    parts = full_string.strip().split()
    for part in parts:
        if part[0] == '(':
            part = part[1:]
        if part[-1] in [')',',']:
            part = part[0:-1]
        if 'stream:' in part:
            pidstr = part.split(':')[1]
            break
    if pidstr is None:
        print("failed to retrieve stream ID from '%s'" % full_string)
        sys.exit(1)
    device,stream = pidstr.split('.')
    fake_tid = int(stream)
    fake_pid = -((int(device)+1)*10000)
    hip_stream_pids[fake_pid] = device
    return fake_pid,fake_tid

def hash_pid_agent(pid, agent):
    return int(agent)/int(pid)

for filename in non_opt_args:
    if not os.path.isfile(filename):
        print("Skipping '%s': not a file" % filename)
        continue
    if output_filename == filename:
        # skip the output filename we just created; it's not an input file
        continue

    # the JSON attempt above consumes the open file lines, so re-open
    with open(filename) as input_file:
        for line in input_file:
            match = None

            #compile(r"  hip-api pid:(\d+) tid:(\d+) (.*) ret=(.*)>> \+(\d+)")
            match = RE_HIP.search(line)
            if match:
                count_hip_api += 1
                pid,tid,func,retcode,ts,dur = match.groups()
                pid = get_hiprocclr_pid(pid)
                hip_pids[pid] = None
                ts = int(ts)/1000
                dur = int(dur)/1000
                out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":%s, "pid":%d, "tid":%s},\n'%(
                    func, ts, dur, pid, tid))
                continue

            if 'HIP:' in line:
                count_hip_missed += 1
                continue

            match = RE_HSA.search(line)
            if match:
                count_hsa_api += 1
                pid,tid,func,args,retcode,ts,dur = match.groups()
                pid = -int(pid)
                hsa_pids[pid] = None
                ts = int(ts)/1000
                dur = int(dur)/1000
                if '\\' in args:
                    print("HSA event with bad escape character")
                    out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":%s, "pid":%d, "tid":%s},\n'%(
                        func, ts, dur, pid, tid))
                else:
                    out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":%s, "pid":%d, "tid":%s, "args":{"params":"%s"}},\n'%(
                        func, ts, dur, pid, tid, args))
                continue

            match = RE_HSA_DISPATCH_HOST.search(line)
            if match:
                count_hsa_dispatch_host += 1
                pid,tid,queue,agent,signal,name,tick,did,wgx,wgy,wgz,gx,gy,gz = match.groups()
                workgroups[(int(wgx)*int(wgy)*int(wgz),(wgx,wgy,wgz),name)] = None
                key = (pid,agent)
                if key not in hsa_queues:
                    hsa_queues[key] = {}
                if queue not in hsa_queues[key]:
                    index = len(hsa_queues[key])
                    hsa_queues[key][queue] = index
                tid = hsa_queues[key][queue]
                pid = -int(pid)
                tick = int(tick)/1000
                out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":1, "pid":%s, "tid":%s},\n'%(
                    name, tick, pid, tid))
                if show_flow:
                    out.write('{"name":"%s", "cat":"dispatch", "ph":"s", "ts":%s, "pid":%s, "tid":%s, "id":%s},\n'%(
                        name, tick, pid, tid, did))
                continue

            match = RE_HSA_DISPATCH.search(line)
            if match:
                count_hsa_dispatch += 1
                pid,tid,queue,agent,signal,name,start,stop,did = match.groups()
                new_pid = hash_pid_agent(pid,agent)
                key = (pid,agent)
                if key not in hsa_queues:
                    hsa_queues[key] = {}
                if queue not in hsa_queues[key]:
                    index = len(hsa_queues[key])
                    hsa_queues[key][queue] = index
                tid = hsa_queues[key][queue]
                ts = (int(start)/1000)
                dur = (int(stop)-int(start))/1000
                out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":%s, "pid":%s, "tid":%s},\n'%(
                    name, ts, dur, new_pid, tid))
                if show_flow:
                    out.write('{"name":"%s", "cat":"dispatch", "ph":"f", "ts":%s, "pid":%s, "tid":%s, "id":%s},\n'%(
                        name, ts, new_pid, tid, did))
                continue

            match = RE_HSA_BARRIER_HOST.search(line)
            if match:
                count_hsa_barrier_host += 1
                name = 'barrier'
                pid,tid,queue,agent,signal,dep1,dep2,dep3,dep4,dep5,tick,did = match.groups()
                key = (pid,agent)
                if key not in hsa_queues:
                    hsa_queues[key] = {}
                if queue not in hsa_queues[key]:
                    index = len(hsa_queues[key])
                    hsa_queues[key][queue] = index
                tid = hsa_queues[key][queue]
                pid = -int(pid)
                tick = int(tick)/1000
                out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":1, "pid":%s, "tid":%s, "args":{"dep1":"%s","dep2":"%s","dep3":"%s","dep4":"%s","dep5":"%s"}},\n'%(
                    name, tick, pid, tid, dep1, dep2, dep3, dep4, dep5))
                if show_flow:
                    out.write('{"name":"%s", "cat":"barrier", "ph":"s", "ts":%s, "pid":%s, "tid":%s, "id":%s},\n'%(
                        name, tick, pid, tid, did))
                continue

            match = RE_HSA_BARRIER.search(line)
            if match:
                count_hsa_barrier += 1
                name = 'barrier'
                pid,tid,queue,agent,signal,start,stop,dep1,dep2,dep3,dep4,dep5,did = match.groups()
                new_pid = hash_pid_agent(pid,agent)
                key = (pid,agent)
                if key not in hsa_queues:
                    hsa_queues[key] = {}
                if queue not in hsa_queues[key]:
                    index = len(hsa_queues[key])
                    hsa_queues[key][queue] = index
                tid = hsa_queues[key][queue]
                ts = (int(start)/1000)
                dur = (int(stop)-int(start))/1000
                out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":%s, "pid":%s, "tid":%s, "args":{"dep1":"%s","dep2":"%s","dep3":"%s","dep4":"%s","dep5":"%s"}},\n'%(
                    name, ts, dur, new_pid, tid, dep1, dep2, dep3, dep4, dep5))
                if show_flow:
                    out.write('{"name":"%s", "cat":"barrier", "ph":"f", "ts":%s, "pid":%s, "tid":%s, "id":%s},\n'%(
                        name, ts, new_pid, tid, did))
                continue

            match = RE_HSA_COPY.search(line)
            if match:
                count_hsa_copy += 1
                name = 'copy'
                pid,tid,agent,signal,start,stop,dep1,dep2,dep3,dep4,dep5 = match.groups()
                new_pid = hash_pid_agent(pid,agent)
                key = (pid,agent)
                if key not in hsa_queues:
                    hsa_queues[key] = {}
                #tid = hsa_queues[key][queue]
                tid = -1
                ts = (int(start)/1000)
                dur = (int(stop)-int(start))/1000
                out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":%s, "pid":%s, "tid":%s, "args":{"dep1":"%s","dep2":"%s","dep3":"%s","dep4":"%s","dep5":"%s"}},\n'%(
                    name, ts, dur, new_pid, tid, dep1, dep2, dep3, dep4, dep5))
                continue

            if 'HSA:' in line:
                count_hsa_missed += 1
                if count_hsa_missed == 1:
                    print(line)
                continue

            # look for most specific HCC profile first
            match = RE_HCC_PROF_TS_OPX.search(line)
            if match:
                count_hcc_prof_ts_opx += 1
                optype,msg,us,start,stop,opnum,extra = match.groups()
                extra = ' '.join(extra.strip().split()).strip() # normalize whitespace in extra text
                opnum_parts = opnum.split('.')
                if len(opnum_parts) != 3:
                    print("RE_HCC_PROF_TS_OPX: HCC event sequence number not recognized '%s'" % opnum)
                    sys.exit(1)
                # these are fake -- pid is GPU device ID, tid is stream ID
                # we use negative offsets for GPU device ID so they don't collide with TensorFlow
                pid = -int(opnum_parts[0])-1
                devices[pid] = None
                tid = opnum_parts[1]
                seqnum = opnum_parts[2]
                if extra:
                    args = '{"seqNum":%s, "extra":"%s"}' % (seqnum,extra)
                else:
                    args = '{"seqNum":%s}' % seqnum
                ts = (int(start)/1000)
                dur = (int(stop)-int(start))/1000
                #ts = int(start)
                #dur = int(stop)-int(start)
                out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":%s, "pid":%s, "tid":%s, "args":%s},\n'%(
                    msg, ts, dur, pid, tid, args))
                # we do not log barriers for gap analysis
                if show_gaps and "depcnt" not in msg:
                    if pid not in gaps:
                        gaps[pid] = {}
                        gap_names[pid] = {}
                    if ts in gaps[pid]:
                        count_gap_duplicate_ts += 1
                        vprint("duplicate timestamp found in gap analysis, pid:%s ts:%s" % (pid,ts))
                        if dur > gaps[pid][ts]:
                            vprint("replacing with longer dur %s >  %s for name:%s" % (dur, gaps[pid][ts], msg))
                            gaps[pid][ts] = dur
                            gap_names[pid][ts] = msg
                        else:
                            vprint("keeping existing      dur %s >= %s for name:%s" % (gaps[pid][ts], dur, msg))
                    else:
                        gaps[pid][ts] = dur
                        gap_names[pid][ts] = msg
                continue

            match = RE_HCC_PROF_TS_OP.search(line)
            if match:
                count_hcc_prof_ts_op += 1
                optype,msg,us,start,stop,opnum = match.groups()
                opnum_parts = opnum.split('.')
                if len(opnum_parts) != 3:
                    print("RE_HCC_PROF_TS_OP: HCC event sequence number not recognized '%s'" % opnum)
                    sys.exit(1)
                # these are fake -- pid is GPU device ID, tid is stream ID
                # we use negative offsets for GPU device ID so they don't collide with TensorFlow
                pid = -int(opnum_parts[0])-1
                devices[pid] = None
                tid = opnum_parts[1]
                seqnum = opnum_parts[2]
                args = '{"seqNum":%s}' % seqnum
                out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":%s, "pid":%s, "tid":%s, "args":%s},\n'%(
                    msg, (int(start)/1000), (int(stop)-int(start))/1000, pid, tid, args))
                continue

            match = RE_HCC_PROF_TS.search(line)
            if match:
                count_hcc_prof_ts += 1
                optype,msg,us,start,stop = match.groups()
                continue

            match = RE_HCC_PROF_OP.search(line)
            if match:
                count_hcc_prof_op += 1
                optype,msg,us,extra = match.groups()
                continue

            match = RE_HCC_PROF.search(line)
            if match:
                count_hcc_prof += 1
                optype,msg,us = match.groups()
                continue

            if 'profile:' in line:
                count_hcc_prof_missed += 1
                continue

            match = RE_STRACE_UNFINISED.search(line)
            if match:
                count_strace_unfinished += 1
                ts,ms,text = match.groups()
                text = text.strip()
                if '(' not in text:
                    print("strace unfinished cannot parse function name: %s" % text)
                name = text.split('(')[0]
                strace_unfinished[name] = (text,ts,ms)
                continue

            match = RE_STRACE_RESUMED.search(line)
            #compile(r'(\d+)\.(\d+) <\.\.\. (\w+) resumed> .* = <?(["\w/\.-]+)>? <(.*)>')
            if match:
                count_strace_resumed += 1
                ts,ms,text,retval,dur = match.groups()
                if text not in strace_unfinished:
                    print("strace resumed cannot find corresponding unfinished: %s" % text)
                otext,ots,oms = strace_unfinished[text]
                ts = int(ots)*1000000 + int(oms) # convert s.us to us
                dur = int(float(dur)*1000000)
                otext = "%s)" % otext # adds the closing function paren back in
                escaped_call = json.dumps(otext)
                out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":%s, "pid":%s, "args":{"name":%s}},\n'%(
                    text,ts,dur,-2000,escaped_call))
                continue

            match = RE_STRACE_COMPLETE.search(line)
            #compile(r"(\d+)\.(\d+) (.*) = (-?<?\w+>?) <(.*)>")
            if match:
                count_strace_complete += 1
                ts,ms,text,retval,dur = match.groups()
                text = text.strip()
                ts = int(ts)*1000000 + int(ms) # convert s.us to us
                dur = int(float(dur)*1000000)
                name = text.split('(')[0]
                escaped_call = json.dumps(text)
                out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":%s, "pid":%s, "args":{"name":%s}},\n'%(
                    name,ts,dur,-2000,escaped_call))
                continue

            vprint("unparsed line: %s" % line.strip())
            count_skipped += 1

if hsa_pids:
    for pid in hsa_pids:
        out.write('{"name":"process_name", "ph":"M", "pid":%d, "args":{"name":"HSA"}},\n'%pid)

if count_hsa_dispatch or count_hsa_barrier or count_hsa_copy:
    for pid,agent in hsa_queues:
        out.write('{"name":"process_name", "ph":"M", "pid":%s, "args":{"name":"HSA Agent for pid %s agent %s"}},\n'%(hash_pid_agent(pid,agent),pid,agent))

if count_strace_resumed + count_strace_complete > 0:
    out.write('{"name":"process_name", "ph":"M", "pid":-2000, "args":{"name":"strace/ltrace"}},\n')

if hip_pids:
    for pid in hip_pids:
        out.write('{"name":"process_name", "ph":"M", "pid":%s, "args":{"name":"HIP"}},\n'%pid)

if hip_stream_output:
    for pid in hip_stream_pids:
        pidstr = hip_stream_pids[pid]
        out.write('{"name":"process_name", "ph":"M", "pid":%s, "args":{"name":"HIP Stream Device %s"}},\n'%(pid,pidstr))

for fake in devices:
    dev = -(fake + 1)
    out.write('{"name":"process_name", "ph":"M", "pid":%s, "args":{"name":"HCC GPU %s"}},\n'%(fake,dev))

def get_gap_name(dur):
    gaps_default = [10, 20, 50, 100, 1000, 10000, 100000]
    for interval in gaps_default:
        if dur < interval:
            return "gap%s" % interval
    return "gapHUGE"

if show_gaps:
    for fake in sorted(gaps):
        dev = -(fake + 1)
        pid = fake-1000 # something unique from fake HCC GPU pid
        g = gaps[fake]
        out.write('{"name":"process_name", "ph":"M", "pid":%s, "args":{"name":"GAP GPU %s"}},\n'%(pid,dev))
        prev_ts = None
        prev_dur = None
        prev_end = None
        for ts in sorted(g):
            dur = g[ts]
            if not prev_end:
                prev_ts = ts
                prev_dur = dur
                prev_end = ts+dur
                continue
            # check whether the next duration fits inside the previous one, and skip if so
            if ts < prev_end and ts+dur < prev_end:
                count_gap_wrapped += 1
                vprint("event completely inside another ts:%s ts+dur:%s prev_end:%s name:%s wrapped_by:%s" % (
                    ts, ts+dur, prev_end, gap_names[fake][ts][0:40], gap_names[fake][prev_ts][0:40]))
                continue
            else:
                count_gap_okay += 1
            gap_dur = ts - prev_end
            out.write('{"name":"%s", "ph":"X", "ts":%s, "dur":%s, "pid":%s, "tid":%s},\n'%(
                get_gap_name(gap_dur), prev_end, gap_dur, pid, 0))
            prev_ts = ts
            prev_dur = dur
            prev_end = ts+dur




# write an empty event so we don't need to clean up the last extra comma
out.write("""{}
]
}
""")

print("    total skipped lines: %d"%count_skipped)
print("          api hsa lines: %d"%count_hsa_api)
print("host dispatch hsa lines: %d"%count_hsa_dispatch_host)
print("     dispatch hsa lines: %d"%count_hsa_dispatch)
print(" host barrier hsa lines: %d"%count_hsa_barrier_host)
print("      barrier hsa lines: %d"%count_hsa_barrier)
print("         copy hsa lines: %d"%count_hsa_copy)
print("       missed hsa lines: %d"%count_hsa_missed)
print("          api hip lines: %d"%count_hip_api)
print("       missed hip lines: %d"%count_hip_missed)
print("  prof ts opx hcc lines: %d"%count_hcc_prof_ts_opx)
print("   prof ts op hcc lines: %d"%count_hcc_prof_ts_op)
print("      prof ts hcc lines: %d"%count_hcc_prof_ts)
print("      prof op hcc lines: %d"%count_hcc_prof_op)
print("         prof hcc lines: %d"%count_hcc_prof)
print("       missed hcc lines: %d"%count_hcc_prof_missed)
print("unfinished strace lines: %d"%count_strace_unfinished)
print("   resumed strace lines: %d"%count_strace_resumed)
print("  complete strace lines: %d"%count_strace_complete)
print("       duplicate gap ts: %d"%count_gap_duplicate_ts)
print("      wrapped gap event: %d"%count_gap_wrapped)
print("         okay gap event: %d"%count_gap_okay)

if print_workgroups:
    for size,(x,y,z),name in sorted(workgroups):
        print(size,(x,y,z),name)
